# transformer-from-scratch
Implement the Transformer from scratch in PyTorch â€” multi-head attention, positional encoding, encoder-decoder. No Hugging Face, no API keys.
